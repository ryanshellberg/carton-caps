from services.knowledge_base_service import KnowledgeBaseService
from clients.openai_client import OpenAIClient
from request.messages.message import Message


class ContextManager:
    @staticmethod
    def get_context_for_response(message: Message) -> str:
        """Gather's relevant contextual information for a message.

        Fetches:
        1. Relevant documents from the knowledge base using the embeddings generated by the user's query.
        2. Relevant and anonymized user context. Currently mocked out for this prototype.

        Args:
            message: The Message containing the user's prompt.

        Returns:
            A string containing all gathered context, formatted appropriately for inclusion in an LLM prompt.
        """

        user_text_embeddings = OpenAIClient.get_embeddings(message.user_text)
        relevant_document_texts = KnowledgeBaseService.get_matching_documents(
            user_text_embeddings
        )
        all_document_text = "\n".join(relevant_document_texts)

        user_context = "Purchase history: 5 eggs."

        all_context = f"""USER_CONTEXT:
```
{user_context}
```

RELEVANT_DOCUMENT_CONTEXT:
```
{all_document_text}
```
"""

        return all_context
